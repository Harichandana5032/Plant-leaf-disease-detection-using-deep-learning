import os
import sys
import io
import numpy as np
import tensorflow as tf
from tensorflow import keras
from keras._tf_keras.keras.preprocessing.image import load_img, img_to_array
from keras._tf_keras.keras.models import load_model
from flask import Flask, request, render_template, jsonify
from werkzeug.utils import secure_filename

app = Flask(__name__)

# Ensure 'uploads' directory exists
if not os.path.exists('uploads'):
    os.makedirs('uploads')

# Load the pre-trained model
try:
    model = load_model('model.h5')
    print('Model loaded. Check http://127.0.0.1:5000/')
except Exception as e:
    print(f"Error loading model: {e}")
    model = None

# Define labels for predictions
labels = {0: 'Healthy', 1: 'Powdery', 2: 'Rust'}
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

def getResult(image_path):
    try:
        print(f"Processing image: {image_path}")
        img = load_img(image_path, target_size=(225, 225))
        x = img_to_array(img)
        x = x.astype('float32') / 255.0
        x = np.expand_dims(x, axis=0)
        predictions = model.predict(x)
        print(f"Predictions: {predictions}")
        return predictions
    except Exception as e:
        print(f"Error in getResult: {e}")
        return None

@app.route('/', methods=['GET'])
def index():
    return render_template('index.html')

@app.route('/predict', methods=['GET', 'POST'])
def upload():
    try:
        if 'file' not in request.files:
            return jsonify({"error": "No file part in the request"}), 400

        f = request.files['file']
        if f.filename == '':
            return jsonify({"error": "No file selected for uploading"}), 400

        basepath = os.path.dirname(__file__)
        file_path = os.path.join(basepath, 'uploads', secure_filename(f.filename))
        f.save(file_path)

        predictions = getResult(file_path)
        if predictions is None:
            return jsonify({"error": "Prediction failed."}), 500

        predicted_label = labels[np.argmax(predictions)]
        return jsonify({"prediction": predicted_label})
    except Exception as e:
        return jsonify({"error": str(e)}), 500

if __name__ == '__main__':
    if model:
        app.run(debug=True)
    else:
        print("Model failed to load. Exiting...")
